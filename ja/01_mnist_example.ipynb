{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MNIST分類モデルの構築とTensorBoardによる可視化\n",
    "\n",
    "ここでは、MNISTを題材にして、TensorBoardの機能を解説します。\n",
    "\n",
    "[Hands-on TensorBoard (TensorFlow Dev Summit 2017)](https://www.youtube.com/watch?v=eBbEDRsCmv4) をベースにしています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. 前準備\n",
    "\n",
    "必要なライブラリをインポートし、MNISTのデータをダウンロードします。\n",
    "\n",
    "MNISTは、0 から 9 までの手書き画像を分類する、有名な問題とデータ・セットのことです。画像データは全て $28\\times28$ ピクセルです。\n",
    "TensorFlow のチュートリアルでも利用されており、\n",
    "```\n",
    "tensorflow.examples.tutorials.mnist\n",
    "```\n",
    "に MNIST 専用の便利関数があります。MNISTのデータは $28\\times28 = 786$ 次元の実数値ベクトルとして表現されています。\n",
    "各画像には 0 から 9 のラベルが one hot 表現で付与されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# TensorBoardによる可視化\n",
    "from google.datalab.ml._tensorboard import TensorBoard\n",
    "# Jupyter Notebook 上での可視化\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_style({'axes.grid' : False}) # グリッドを非表示とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "label of image0: [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAF2CAYAAABgYlPrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njtADgHGEHgCM+zdRnpfY7R0WbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d6050bdd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label of image1: [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAF2CAYAAABgYlPrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAMTQAADE0B0s6tTgAAFGtJREFUeJzt3X9o1Pcdx/HXRcnJojbk1yUZFymjJAtYB83yVxch2Eb9\nI1pGqW1i80ejbH9UMA4TcUucE61UoXV/VFpDCoq2UIgZWpJhy0L/GQ5bEFxkEEp67eVicrFFmKtd\n8tkfo9fZ6nqf3PfyTd8+H3B/3N377j7Hxadfz7tPIs45JwCAWQVhLwAAkF+EHgCMI/QAYByhBwDj\nCD0AGEfoAcC45WE9cENDY1gPDQCmlJSU6M9/Hr7v9ZGwPkcfiUTCeFgAMKeiIqapqdR9rw/krZuJ\niQlt27ZNLS0tevrppzU+Ph7E3QIAAhBI6Ht7e7Vt2zaNjIyos7NT3d3dQdwtACAAOYd+dnZW165d\nU2trqySppaVFqVRKiUQi58UBAHKXc+gnJydVXl6ugoJv7qqqqkrJZDLXuwYABCAvH69knzQAWDpy\nDn1VVZWmp6c1Pz+fuSyVSqm6ujrXuwYABCDn0JeUlKi+vl5DQ0OSpOHhYVVWVioej+e8OABA7gL5\nHP3HH3+sffv26ebNm1q1apWOHDmiRx555P8/MJ+jB4BAfN/n6PnCFAD8wC3KF6YAAEsXoQcA4wg9\nABhH6AHAOEIPAMYRegAwjtADgHGEHgCMI/QAYByhBwDjCD0AGEfoAcA4Qg8AxhF6ADCO0AOAcYQe\nAIwj9ABgHKEHAOMIPQAYR+gBwDhCDwDGEXoAMI7QA4BxhB4AjCP0AGAcoQcA4wg9ABhH6AHAOEIP\nAMYRegAwjtADgHGEHgCMI/QAYByhBwDjCD0AGEfoAcA4Qg8AxhF6ADCO0AOAcYQeAIwj9ABgHKEH\nAOMIPQAYR+gBwDhCDwDGEXoAMI7QA4BxhB4AjCP0AGAcoQcA45aHvQBgMa1Zs8Zr/oUXXvB+jP37\n93vNO+e8H8PH2NiY1/zvfvc7r/nz5897zWPxcUQPAMYFckTf3NysaDSqaDSqSCSinTt3atOmTUHc\nNQAgR4GEPhKJ6JVXXlFtbW0QdwcACFAgb9045/L+PiMAYGEC+8/Y7u5uOef06KOPqqurSyUlJUHd\nNQAgB4Ec0Z89e1ZDQ0MaHBxUcXGxenp6grhbAEAAAgl9ZWWlJGnZsmXq6OjQlStXgrhbAEAAcg79\n7du3devWrcz5CxcuqL6+Pte7BQAEJOf36GdmZrRr1y7Nz8/LOad4PK6jR48GsTYAQAByDn08Htfg\n4GAQawEA5AHfjAUA4yIupA/ARyKRMB4WS1x5ebnXvO8nvNra2rzmS0tLveYlqaDA7/jJ94+g75+d\n+fl5r/lPPvnEa76xsdFrXpLS6bT3bXB/FRUxTU2l7ns9R/QAYByhBwDjCD0AGEfoAcA4Qg8AxhF6\nADCO0AOAcYQeAIwj9ABgHKEHAOMIPQAYF9ivEgTuZf/+/V7zBw8e9JrP9z4xC9kKKpFIeM1PT097\nP4aPsrIyr/mHH37Ya/4vf/mL17wkrV271vs2WDiO6AHAOEIPAMYRegAwjtADgHGEHgCMI/QAYByh\nBwDjCD0AGEfoAcA4Qg8AxhF6ADCO0AOAcWxqhrzasmVL2Eu4i+8mZX//+9+9H6O5udlrfmZmxmve\nd2O2xx9/3Gved5Oy2tpar3ksPo7oAcA4Qg8AxhF6ADCO0AOAcYQeAIwj9ABgHKEHAOMIPQAYR+gB\nwDhCDwDGEXoAMC7ifDf/COqBPffrQPjq6uq8b3P58mWv+dnZWa/56enpvM7v2bPHa16Sdu3a5TV/\n+PBhr/lEIuE17/tnbW5uzmt+fn7ea16Sfv3rX3vNv/HGG96P8SCpqIhpaip13+s5ogcA4wg9ABhH\n6AHAOEIPAMYRegAwjtADgHGEHgCMI/QAYByhBwDjCD0AGEfoAcC45WEvAD8c169f975NY2Oj1/zM\nzExe5333fdmxY4fXvCR1dnZ6zb/++ute87573WzdutVr3nf7q4VslzU4OOh9GywcR/QAYFxWoT90\n6JCam5tVV1d311HdxMSEtm3bppaWFj399NMaHx/P20IBAAuTVeg3btyoc+fO6cc//vFdl/f29mrb\ntm0aGRlRZ2enuru787JIAMDCZRX6hoYGxWKxu96Lm52d1bVr19Ta2ipJamlpUSqV8n7/EACQXwt+\nj35yclLl5eUqKPjmLqqqqpRMJgNZGAAgGIH+Z2xIv6wKAPB/LDj0VVVVmp6evuvXiKVSKVVXVwey\nMABAMBYc+pKSEtXX12toaEiSNDw8rMrKSsXj8cAWBwDIXVZfmOrt7dXo6KjS6bQ6OztVVFSkkZER\n/f73v9e+fft08uRJrVq1SkeOHMn3egEAnrIK/cGDB+95+cMPP6y33nor0AUBAILFN2MBwDj2ukFe\nLWR/nHzy/WTY9PS092P84x//8JqfnZ31mt+9e7fXfL6/yJhOp71v47tHEXLDET0AGEfoAcA4Qg8A\nxhF6ADCO0AOAcYQeAIwj9ABgHKEHAOMIPQAYR+gBwDhCDwDGsdcNlpRf/OIXXvN1dXVe875714yN\njXnNS1Jtba3X/F//+lev+fLycq/5fO/vs3nzZq95LD6O6AHAOEIPAMYRegAwjtADgHGEHgCMI/QA\nYByhBwDjCD0AGEfoAcA4Qg8AxhF6ADCO0AOAcWxqhiWlra3Na76zs9NrPhKJeM37bgi2kMfw3aTM\n9/5nZma85k+cOOE1/+GHH3rNY/FxRA8AxhF6ADCO0AOAcYQeAIwj9ABgHKEHAOMIPQAYR+gBwDhC\nDwDGEXoAMI7QA4Bx7HUDhMx3P50PPvjAa37Pnj1e8+xdYw9H9ABgHKEHAOMIPQAYR+gBwDhCDwDG\nEXoAMI7QA4BxhB4AjCP0AGAcoQcA4wg9ABjHXjdYUs6ePes1v2bNGq/5srIyr/m6ujqveUn60Y9+\n5DUfiUS85vv6+rzm2bsGHNEDgHFZHdEfOnRI77//vpLJpM6fP585ymlublY0GlU0GlUkEtHOnTu1\nadOmvC4YAOAnq9Bv3LhRO3bs0HPPPXfX5ZFIRK+88opqa2vzsjgAQO6yCn1DQ4Ok7+6b7Zzz3ksb\nALC4cv7P2O7ubjnn9Oijj6qrq0slJSVBrAsAEJCc/jP27NmzGhoa0uDgoIqLi9XT0xPUugAAAckp\n9JWVlZKkZcuWqaOjQ1euXAlkUQCA4Cw49Ldv39atW7cy5y9cuKD6+vpAFgUACE5W79H39vZqdHRU\n6XRanZ2dKioqUn9/v1588UXNz8/LOad4PK6jR4/me70AAE9Zhf7gwYP3vHxwcDDQxQAAgsc3YwHA\nuIgL6YPwvvt7AGH46U9/6n2bP/zhD17zW7Zs8Zr33btm8+bNXvPpdNprHuGrqIhpaip13+s5ogcA\n4wg9ABhH6AHAOEIPAMYRegAwjtADgHGEHgCMI/QAYByhBwDjCD0AGEfoAcA49rpZwsrKyrzmZ2Zm\n8rQS+PD92X733Xe95p988kmv+a6uLq/5V1991Wse4WOvGwB4wBF6ADCO0AOAcYQeAIwj9ABgHKEH\nAOMIPQAYR+gBwDhCDwDGEXoAMI7QA4Bxy8NewIOkqanJa/7YsWNe82NjY17zHR0dXvPIju/2UYcP\nH/aaf+KJJ7zma2trveZhD0f0AGAcoQcA4wg9ABhH6AHAOEIPAMYRegAwjtADgHGEHgCMI/QAYByh\nBwDjCD0AGEfoAcA4NjXLQXl5udf8a6+95jV/48YNr3k2KVsaioqKvOZ9fy4ikYjXPMARPQAYR+gB\nwDhCDwDGEXoAMI7QA4BxhB4AjCP0AGAcoQcA4wg9ABhH6AHAOEIPAMax100OnnrqKa/52tpar/nR\n0VGveQSvrq7O+zbvvPOO17zvz4Vzzmv++vXrXvOwhyN6ADAuqyP6O3fuaPfu3RofH9eKFStUWlqq\nvr4+1dTUaHZ2Vnv37lUikVBhYaH6+vrU0NCQ73UDALKU9RH9M888o+HhYZ0/f17Nzc3av3+/JOnl\nl1/Wz372M42MjOjw4cPas2eP5ubm8rZgAICfrEJfWFiopqamzPl169YpmUxKkoaHh/Xss89Kktau\nXatYLKbLly/nYakAgIVY0Hv0p0+f1oYNG/T5559rbm5OpaWlmeuqq6s1OTkZ2AIBALnxDv3Jkyc1\nMTGhrq4uSd/9bTe+nwgAAOSXV+j7+/t16dIlnTp1StFoVMXFxSooKFA6nc7MJJNJVVVVBb5QAMDC\nZB36gYEBXbx4UQMDA1q5cmXm8o0bN+rcuXOSpKtXr+rGjRtqbGwMfqUAgAXJ6uOVU1NTOnr0qGpq\navT888/LOadoNKq3335bv/nNb7R37161tLSosLBQx44d07Jly/K9bgBAlrIKfSwWu++360pLS9Xf\n3x/oogAAweGbsQBgHHvd5OCDDz7wmi8o8Pt79X+/u5CNtrY2r/mxsTGv+Q8//NBrfiHWrFnjNf/4\n4497zfvuT7R161aveem7n0T7Pr6fVHv11Ve95k+cOOE1D3s4ogcA4wg9ABhH6AHAOEIPAMYRegAw\njtADgHGEHgCMI/QAYByhBwDjCD0AGEfoAcC4iAvpV0L57gdiwTvvvOM1v2XLFq/5fO+x8tFHH3nN\nL0RNTY3X/P/+GstsLMWfu8OHD3vN++5dMzMz4zWPH56KipimplL3vZ4jegAwjtADgHGEHgCMI/QA\nYByhBwDjCD0AGEfoAcA4Qg8AxhF6ADCO0AOAcYQeAIxjr5tFVFFR4TV/8eJFr/nHHnvMa34xXnrf\nx8j3fj3//Oc/veavX7/uNS9JR44c8ZofHBz0fgzgf7HXDQA84Ag9ABhH6AHAOEIPAMYRegAwjtAD\ngHGEHgCMI/QAYByhBwDjCD0AGEfoAcA49rpZwsrLy73mDx48mKeV/NeOHTu8b+O7j8vMzIzXvO+P\n74kTJ7zmF7LXDbDY2OsGAB5whB4AjCP0AGAcoQcA4wg9ABhH6AHAOEIPAMYRegAwjtADgHGEHgCM\nI/QAYByhBwDj2NQMAH7g2NQMAB5wy7MZunPnjnbv3q3x8XGtWLFCpaWlOnDggOLxuLZv365kMqnV\nq1dLkrZu3aqOjo68LhoA4MFl4csvv3Sjo6OZ82fOnHHbt293zjnX3t7u3nvvvWzu5i6SOHHixIlT\nAKeKitj/7W1Wb90UFhaqqakpc37dunX67LPPMudDepsfAJCFBb1Hf/r0aW3YsCFz/vjx42ptbVVX\nV5cSiURgiwMABMD3LZfXXnvNPfPMM+5f//qXc865VCqVue7MmTNu8+bNvHXDiRMnTot4CuStm6/1\n9/fr0qVLOnXqlKLRqCQpFotlrm9ra1MikdAXX3zhc7cAgDzKOvQDAwO6ePGiBgYGtHLlSknS3Nyc\n0ul0ZmZkZERlZWV66KGHgl8pAGBBsvrC1NTUlNavX6+amhoVFRXJOadoNKo333xT7e3t+uqrrxSJ\nRFRSUqKenh7V1tZ+/wPzhSkACMT3fWGKb8YCwA8c34wFgAccoQcA4wg9ABhH6AHAOEIPAMYRegAw\njtADgHGEHgCMI/QAYByhBwDjCD0AGEfoAcA4Qg8AxhF6ADCO0AOAcYQeAIwj9ABgHKEHAOMIPQAY\nR+gBwDhCDwDGEXoAMI7QA4BxhB4AjCP0AGDc8rAe2DkX1kMDwAOFI3oAMI7QA4BxhB4AjCP0AGAc\noQcA4wg9ABhH6AHAOEIPAMaF9oWpb5uYmFB3d7du3ryp1atX66WXXtJPfvKTsJeVV83NzYpGo4pG\no4pEItq5c6c2bdoU9rICdejQIb3//vtKJpM6f/686urqJNl+ve/3nK2+3nfu3NHu3bs1Pj6uFStW\nqLS0VH19faqpqdHs7Kz27t2rRCKhwsJC9fX1qaGhIewl5+xez/nAgQOKx+Pavn27ksmkVq9eLUna\nunWrOjo6wl2wWyKef/55Nzg46Jxzbnh42P3yl78MeUX519zc7K5fvx72MvLqb3/7m0ulUq65udmN\njY1lLrf8et/vOVt9vb/88ks3OjqaOX/mzBnX3t7unHOup6fH/fGPf3TOOXf16lXX1NTk/v3vf4ey\nziDd6zlv377dOedce3u7e++998Ja2j0tibduZmdnde3aNbW2tkqSWlpalEqllEgkQl5ZfjnnzG8F\n0dDQoFgsdtfztP563+s5S3Zf78LCQjU1NWXOr1u3TslkUpI0PDysZ599VpK0du1axWIxXb58OZR1\nBulez/mzzz7LnF9qr/OSCP3k5KTKy8tVUPDNcqqqqjI/LJZ1d3ertbVVv/3tbzU7Oxv2chYFr7ft\n1/v06dPasGGDPv/8c83Nzam0tDRzXXV1tSYnJ0NcXX58/Zy/dvz4cbW2tqqrq2tJHMAsidDfy1L7\nGzEfzp49q6GhIQ0ODqq4uFg9PT1hLyk0vN42nDx5UhMTE+rq6pIkRSKRu663+Dp/+zkfO3ZM7777\nrv70pz/pscce069+9auQV7hEQl9VVaXp6WnNz89nLkulUqqurg5xVflXWVkpSVq2bJk6Ojp05cqV\nkFe0OHi9bb7e/f39unTpkk6dOqVoNKri4mIVFBQonU5nZpLJpKqqqkJcZbC+/ZwlKRaLZa5va2tT\nIpHQF198EdYSJS2R0JeUlKi+vl5DQ0OS/vu+XmVlpeLxeMgry5/bt2/r1q1bmfMXLlxQfX19iCta\nPLze9l7vgYEBXbx4UQMDA1q5cmXm8o0bN+rcuXOSpKtXr+rGjRtqbGwMa5mButdznpubu+svtpGR\nEZWVlemhhx4Ka5mSpIhbIv+W+vjjj7Vv3z7dvHlTq1at0pEjR/TII4+Evay8SSQS2rVrl+bn5+Wc\nUzwe1/79+80d1fb29mp0dFTpdFrFxcUqKirSyMiI6df7Xs+5v79fL774osnXe2pqSuvXr1dNTY2K\niorknFM0GtXbb7+tdDqtvXv36tNPP1VhYaF6e3v185//POwl5+x+z/nNN99Ue3u7vvrqK0UiEZWU\nlKinp0e1tbWhrnfJhB4AkB9L4q0bAED+EHoAMI7QA4BxhB4AjCP0AGAcoQcA4wg9ABhH6AHAuP8A\nTDuGg38tmLkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d513bb190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MNISTのデータのダウンロードと展開\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "print\n",
    "print('label of image0: {}'.format(mnist.train.labels[0]))\n",
    "plt.imshow(mnist.train.images[0].reshape(28, 28), cmap='gray', interpolation='none')\n",
    "plt.show()\n",
    "print('label of image1: {}'.format(mnist.train.labels[1]))\n",
    "plt.imshow(mnist.train.images[1].reshape(28, 28), cmap='gray', interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. 初期モデルの構築\n",
    "\n",
    "まずは初期モデルとして、下記のネットワークを構成します\n",
    "\n",
    "![mnist](img/mnist_arch.png)\n",
    "\n",
    "2つの畳み込み層と2つの全結合層をもつ、単純なネットワークです。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは畳み込み層と全結合層を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_layer(input, channels_in, channels_out):\n",
    "    w = tf.Variable(tf.zeros([5, 5, channels_in, channels_out]))\n",
    "    b = tf.Variable(tf.zeros([channels_out]))\n",
    "    conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    act = tf.nn.relu(conv + b)\n",
    "    return act\n",
    "\n",
    "def fc_layer(input, channels_in, channels_out):\n",
    "    w = tf.Variable(tf.zeros([channels_in, channels_out]))\n",
    "    b = tf.Variable(tf.zeros([channels_out]))\n",
    "    act = tf.nn.relu(tf.matmul(input, w) + b)\n",
    "    return act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、それらの層をつなげて、グラフを構築します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "conv1 = conv_layer(x_image, 1, 4)\n",
    "pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "conv2 = conv_layer(pool1, 4, 8)\n",
    "pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "flattened = tf.reshape(pool2, [-1, (28/2/2)*(28/2/2)*8])\n",
    "fc1 = fc_layer(flattened, flattened.get_shape()[1], 128)\n",
    "logits = fc_layer(fc1, 128, 10)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "  tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    ")\n",
    "train_step = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、セッションを生成して、学習のステップを進めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 250, training accuracy 0.09\n",
      "step 500, training accuracy 0.13\n",
      "step 750, training accuracy 0.14\n",
      "step 1000, training accuracy 0.11\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1, 1001):\n",
    "        batch = mnist.train.next_batch(100)\n",
    "        if i%250 == 0:\n",
    "            train_acurracy = sess.run(accuracy, feed_dict={x: batch[0], y: batch[1]})\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_acurracy))\n",
    "      \n",
    "    # Run the training step\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy が 0.1 程度から上がらず、うまく学習できていないことがわかりました。\n",
    "原因特定のため、これからTensorBoardを使ってグラフを可視化します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. TensorBoard によるグラフの可視化\n",
    "\n",
    "まずはグラフを可視化します。\n",
    "\n",
    "```\n",
    "writer = tf.summary.FileWriter('logs/1')\n",
    "writer.add_graph(sess.graph)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('logs/1')\n",
    "    writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 19248. Click <a href=\"/_proxy/44464/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start TensorBoard\n",
    "pid = TensorBoard.start('logs/1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard\n",
    "\n",
    "![TensorBoard01](img/tensorboard-01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stop TensorBoard\n",
    "TensorBoard.stop(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確かにグラフが可視化されましたが、とても複雑に見えます。\n",
    "MNISTでこの状態なので、Inceptionなど、さらに大きなグラフの場合には解釈がとても難しくなります。\n",
    "名前空間をうまく使うことで、この問題は解決できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3. 名前と名前空間\n",
    "\n",
    "http://qiita.com/TomokIshii/items/ffe999b3e1a506c396c8\n",
    "\n",
    "name_scope は variable_scope よりも汎用的。\n",
    "variable_scope は変数のみ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(input, channels_in, channels_out, name=\"conv\"):\n",
    "  with tf.name_scope(name):  # name_scope を追加\n",
    "    w = tf.Variable(tf.zeros([5, 5, channels_in, channels_out]), name=\"W\")  # name を追加\n",
    "    b = tf.Variable(tf.zeros([channels_out]), name=\"B\")  # name を追加\n",
    "    conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")  # name を追加\n",
    "    act = tf.nn.relu(conv + b)\n",
    "  return act\n",
    "\n",
    "def fc_layer(input, channels_in, channels_out, name=\"fc\"):\n",
    "  with tf.name_scope(name):  # name_scope を追加\n",
    "    w = tf.Variable(tf.zeros([channels_in, channels_out]), name=\"W\")  # name を追加\n",
    "    b = tf.Variable(tf.zeros([channels_out]), name=\"B\")  # name を追加\n",
    "    act = tf.nn.relu(tf.matmul(input, w) + b)\n",
    "  return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10], name=\"y\")\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "conv1 = conv_layer(x_image, 1, 32, \"conv1\")\n",
    "pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "conv2 = conv_layer(pool1, 32, 64, \"conv2\")\n",
    "pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "num_elements = pool2.get_shape()[1:].num_elements()\n",
    "flattened = tf.reshape(pool2, [-1, num_elements])\n",
    "\n",
    "fc1 = fc_layer(flattened, flattened.get_shape()[1], 1024, \"fc1\")\n",
    "logits = fc_layer(fc1, 1024, 10, \"fc2\")\n",
    "\n",
    "with tf.name_scope(\"xent\"):  # name_scope を追加\n",
    "  cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "  )\n",
    "with tf.name_scope(\"train\"):  # name_scope を追加\n",
    "  train_step = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "with tf.name_scope(\"accuracy\"):  # name_scope を追加\n",
    "  correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "  writer = tf.summary.FileWriter('logs/2')\n",
    "  writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 19440. Click <a href=\"/_proxy/35756/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start TensorBoard\n",
    "pid = TensorBoard.start('logs/2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard\n",
    "\n",
    "![TensorBoard02](img/tensorboard-02.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TensorBoard.stop(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4. サマリの収集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の4種類の関数で summary を取得する\n",
    "\n",
    "- tf.summary.histogram\n",
    "- tf.summary.image\n",
    "- tf.summary.audio\n",
    "- tf.summary.tensor (under developing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(input, channels_in, channels_out, name=\"conv\"):\n",
    "  with tf.name_scope(name):\n",
    "    w = tf.Variable(tf.zeros([5, 5, channels_in, channels_out]), name=\"W\")\n",
    "    b = tf.Variable(tf.zeros([channels_out]), name=\"B\")\n",
    "    conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    act = tf.nn.relu(conv + b)\n",
    "    tf.summary.histogram(\"weights\", w)  # 追加\n",
    "    tf.summary.histogram(\"biases\", b)  # 追加\n",
    "    tf.summary.histogram(\"activations\", act)  # 追加\n",
    "  return act\n",
    "\n",
    "def fc_layer(input, channels_in, channels_out, name=\"fc\"):\n",
    "  with tf.name_scope(name):\n",
    "    w = tf.Variable(tf.zeros([channels_in, channels_out]), name=\"W\")\n",
    "    b = tf.Variable(tf.zeros([channels_out]), name=\"B\")\n",
    "    act = tf.nn.relu(tf.matmul(input, w) + b)\n",
    "    tf.summary.histogram(\"weights\", w)  # 追加\n",
    "    tf.summary.histogram(\"biases\", b)  # 追加\n",
    "    tf.summary.histogram(\"activations\", act)  # 追加\n",
    "  return act\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10], name=\"y\")\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "tf.summary.image('input', x_image)\n",
    "conv1 = conv_layer(x_image, 1, 4, \"conv1\")\n",
    "pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "conv2 = conv_layer(pool1, 4, 8, \"conv2\")\n",
    "pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "num_elements = pool2.get_shape()[1:].num_elements()\n",
    "flattened = tf.reshape(pool2, [-1, num_elements])\n",
    "\n",
    "fc1 = fc_layer(flattened, flattened.get_shape()[1], 1024, \"fc1\")\n",
    "logits = fc_layer(fc1, 1024, 10, \"fc2\")\n",
    "\n",
    "with tf.name_scope(\"xent\"):\n",
    "  cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "  )\n",
    "  tf.summary.scalar('xent', cross_entropy)  # 追加\n",
    "with tf.name_scope(\"train\"):\n",
    "  train_step = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "  correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "  tf.summary.scalar('acurracy', accuracy)  # 追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 250, training accuracy 0.08\n",
      "step 500, training accuracy 0.09\n",
      "step 750, training accuracy 0.1\n",
      "step 1000, training accuracy 0.11\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "  merged_summary = tf.summary.merge_all()\n",
    "  writer = tf.summary.FileWriter('logs/3')\n",
    "  writer.add_graph(sess.graph)\n",
    "  \n",
    "  for i in range(1, 1001):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    if i % 5 == 0:\n",
    "      s = sess.run(merged_summary, feed_dict={x: batch[0], y: batch[1]})\n",
    "      writer.add_summary(s, i)\n",
    "      \n",
    "    if i%250 == 0:\n",
    "      train_acurracy = sess.run(accuracy, feed_dict={x: batch[0], y: batch[1]})\n",
    "      print(\"step %d, training accuracy %g\" % (i, train_acurracy))\n",
    "\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 19633. Click <a href=\"/_proxy/59979/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pid = TensorBoard.start('logs/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TensorBoard.stop(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-5. バグの原因の特定と解決"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習が進んでいない原因は weights や biases に tf.zeros を指定していたことが原因のように見えるので、そこを変えてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_layer(input, channels_in, channels_out, name=\"conv\"):\n",
    "  with tf.name_scope(name):\n",
    "    w = tf.Variable(tf.truncated_normal([5, 5, channels_in, channels_out], stddev=0.1), name=\"W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[channels_out]), name=\"B\")\n",
    "    conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    act = tf.nn.relu(conv + b)\n",
    "    tf.summary.histogram(\"weights\", w)\n",
    "    tf.summary.histogram(\"biases\", b)\n",
    "    tf.summary.histogram(\"activations\", act)\n",
    "  return act\n",
    "\n",
    "def fc_layer(input, channels_in, channels_out, name=\"fc\"):\n",
    "  with tf.name_scope(name):\n",
    "    w = tf.Variable(tf.truncated_normal([channels_in, channels_out], stddev=0.1), name=\"W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[channels_out]), name=\"B\")\n",
    "    act = tf.nn.relu(tf.matmul(input, w) + b)\n",
    "    tf.summary.histogram(\"weights\", w)\n",
    "    tf.summary.histogram(\"biases\", b)\n",
    "    tf.summary.histogram(\"activations\", act)\n",
    "  return act\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10], name=\"y\")\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "tf.summary.image('input', x_image)\n",
    "conv1 = conv_layer(x_image, 1, 4, \"conv1\")\n",
    "pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "conv2 = conv_layer(pool1, 4, 8, \"conv2\")\n",
    "pool2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "num_elements = pool2.get_shape()[1:].num_elements()\n",
    "flattened = tf.reshape(pool2, [-1, num_elements])\n",
    "flattened_dim = int(flattened.get_shape()[1])\n",
    "\n",
    "fc1 = fc_layer(flattened, flattened_dim, 1024, \"fc1\")\n",
    "logits = fc_layer(fc1, 1024, 10, \"fc2\")\n",
    "\n",
    "with tf.name_scope(\"xent\"):\n",
    "  cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "  )\n",
    "  tf.summary.scalar('xent', cross_entropy)\n",
    "with tf.name_scope(\"train\"):\n",
    "  train_step = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "  correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "  tf.summary.scalar('acurracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 250, training accuracy 0.47\n",
      "step 500, training accuracy 0.65\n",
      "step 750, training accuracy 0.62\n",
      "step 1000, training accuracy 0.53\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "  merged_summary = tf.summary.merge_all()\n",
    "  writer = tf.summary.FileWriter('logs/4')\n",
    "  writer.add_graph(sess.graph)\n",
    "  \n",
    "  for i in range(1, 1001):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    if i % 5 == 0:\n",
    "      s = sess.run(merged_summary, feed_dict={x: batch[0], y: batch[1]})\n",
    "      writer.add_summary(s, i)\n",
    "      \n",
    "    if i%250 == 0:\n",
    "      train_acurracy = sess.run(accuracy, feed_dict={x: batch[0], y: batch[1]})\n",
    "      print(\"step %d, training accuracy %g\" % (i, train_acurracy))\n",
    "\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pid = TensorBoard.start('logs/4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TensorBoard.stop(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, Tuning HyperParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次にパラメータのチューニングをしていきます。\n",
    "実は TensorBoard は指定されたディレクトリを再帰的に読みに行きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pid = TensorBoard.start('logs/hparams')\n",
    "# TensorBoard was started successfully with pid 13166. Click here to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_mnist(learning_rate, n_fc_layers, n_conv_layers, writer):\n",
    "  tf.reset_default_graph()\n",
    "  x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "  y = tf.placeholder(tf.float32, shape=[None, 10], name=\"y\")\n",
    "  x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "  \n",
    "  in_ = x_image\n",
    "  for layer in range(n_conv_layers):\n",
    "    channels_in = int(in_.get_shape()[-1])\n",
    "    channels_out = 2**(layer + 1)\n",
    "    conv = conv_layer(in_, channels_in, channels_out, \"conv{}\".format(layer))\n",
    "    pool = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "    in_ = pool\n",
    "    \n",
    "  num_elements = in_.get_shape()[1:].num_elements()\n",
    "  flattened = tf.reshape(in_, [-1, num_elements])\n",
    "  \n",
    "  in_ = flattened\n",
    "  for layer in range(n_fc_layers):\n",
    "    channels_in = int(in_.get_shape()[-1])\n",
    "    channels_out = 1024\n",
    "    fc = fc_layer(in_, channels_in, channels_out, \"fc{}\".format(layer))\n",
    "    in_ = fc\n",
    "\n",
    "  logits = fc_layer(in_, 1024, 10, \"fc{}\".format(n_fc_layers))\n",
    "  \n",
    "  with tf.name_scope(\"xent\"):\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    )\n",
    "    tf.summary.scalar('xent', cross_entropy)\n",
    "  with tf.name_scope(\"train\"):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "  with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('acurracy', accuracy)\n",
    "    \n",
    "  with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer.add_graph(sess.graph)\n",
    "  \n",
    "    for i in range(1, 2001):\n",
    "      batch = mnist.train.next_batch(100)\n",
    "      if i % 5 == 0:\n",
    "        s = sess.run(merged_summary, feed_dict={x: batch[0], y: batch[1]})\n",
    "        writer.add_summary(s, i)\n",
    "      \n",
    "      if i%250 == 0:\n",
    "        train_acurracy = sess.run(accuracy, feed_dict={x: batch[0], y: batch[1]})\n",
    "        print(\"step %d, training accuracy %g\" % (i, train_acurracy))\n",
    "\n",
    "      sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001_1_1\n",
      "step 250, training accuracy 0.56\n",
      "step 500, training accuracy 0.71\n",
      "step 750, training accuracy 0.71\n",
      "step 1000, training accuracy 0.72\n",
      "step 1250, training accuracy 0.68\n",
      "step 1500, training accuracy 0.76\n",
      "step 1750, training accuracy 0.67\n",
      "step 2000, training accuracy 0.65\n",
      "0.0001_1_2\n",
      "step 250, training accuracy 0.71\n",
      "step 500, training accuracy 0.82\n",
      "step 750, training accuracy 0.8\n",
      "step 1000, training accuracy 0.78\n",
      "step 1250, training accuracy 0.8\n",
      "step 1500, training accuracy 0.85\n",
      "step 1750, training accuracy 0.81\n",
      "step 2000, training accuracy 0.85\n",
      "0.0001_2_1\n",
      "step 250, training accuracy 0.38\n",
      "step 500, training accuracy 0.39\n",
      "step 750, training accuracy 0.49\n",
      "step 1000, training accuracy 0.46\n",
      "step 1250, training accuracy 0.56\n",
      "step 1500, training accuracy 0.54\n",
      "step 1750, training accuracy 0.44\n",
      "step 2000, training accuracy 0.46\n",
      "0.0001_2_2\n",
      "step 250, training accuracy 0.61\n",
      "step 500, training accuracy 0.7\n",
      "step 750, training accuracy 0.75\n",
      "step 1000, training accuracy 0.81\n",
      "step 1250, training accuracy 0.78\n",
      "step 1500, training accuracy 0.78\n",
      "step 1750, training accuracy 0.81\n",
      "step 2000, training accuracy 0.83\n",
      "0.01_1_1\n",
      "step 250, training accuracy 0.14\n",
      "step 500, training accuracy 0.04\n",
      "step 750, training accuracy 0.14\n",
      "step 1000, training accuracy 0.14\n",
      "step 1250, training accuracy 0.06\n",
      "step 1500, training accuracy 0.12\n",
      "step 1750, training accuracy 0.08\n",
      "step 2000, training accuracy 0.1\n",
      "0.01_1_2\n",
      "step 250, training accuracy 0.1\n",
      "step 500, training accuracy 0.09\n",
      "step 750, training accuracy 0.12\n",
      "step 1000, training accuracy 0.06\n",
      "step 1250, training accuracy 0.12\n",
      "step 1500, training accuracy 0.11\n",
      "step 1750, training accuracy 0.15\n",
      "step 2000, training accuracy 0.06\n",
      "0.01_2_1\n",
      "step 250, training accuracy 0.1\n",
      "step 500, training accuracy 0.12\n",
      "step 750, training accuracy 0.08\n",
      "step 1000, training accuracy 0.18\n",
      "step 1250, training accuracy 0.12\n",
      "step 1500, training accuracy 0.12\n",
      "step 1750, training accuracy 0.09\n",
      "step 2000, training accuracy 0.11\n",
      "0.01_2_2\n",
      "step 250, training accuracy 0.1\n",
      "step 500, training accuracy 0.08\n",
      "step 750, training accuracy 0.13\n",
      "step 1000, training accuracy 0.07\n",
      "step 1250, training accuracy 0.14\n",
      "step 1500, training accuracy 0.08\n",
      "step 1750, training accuracy 0.08\n",
      "step 2000, training accuracy 0.09\n",
      "1_1_1\n",
      "step 250, training accuracy 0.11\n",
      "step 500, training accuracy 0.21\n",
      "step 750, training accuracy 0.08\n",
      "step 1000, training accuracy 0.14\n",
      "step 1250, training accuracy 0.1\n",
      "step 1500, training accuracy 0.16\n",
      "step 1750, training accuracy 0.1\n",
      "step 2000, training accuracy 0.1\n",
      "1_1_2\n",
      "step 250, training accuracy 0.11\n",
      "step 500, training accuracy 0.13\n",
      "step 750, training accuracy 0.08\n",
      "step 1000, training accuracy 0.05\n",
      "step 1250, training accuracy 0.12\n",
      "step 1500, training accuracy 0.13\n",
      "step 1750, training accuracy 0.11\n",
      "step 2000, training accuracy 0.11\n",
      "1_2_1\n",
      "step 250, training accuracy 0.09\n",
      "step 500, training accuracy 0.16\n",
      "step 750, training accuracy 0.08\n",
      "step 1000, training accuracy 0.08\n",
      "step 1250, training accuracy 0.09\n",
      "step 1500, training accuracy 0.12\n",
      "step 1750, training accuracy 0.14\n",
      "step 2000, training accuracy 0.12\n",
      "1_2_2\n",
      "step 250, training accuracy 0.12\n",
      "step 500, training accuracy 0.14\n",
      "step 750, training accuracy 0.05\n",
      "step 1000, training accuracy 0.07\n",
      "step 1250, training accuracy 0.1\n",
      "step 1500, training accuracy 0.03\n",
      "step 1750, training accuracy 0.07\n",
      "step 2000, training accuracy 0.08\n"
     ]
    }
   ],
   "source": [
    "for learning_rate in [1e-4, 1e-2, 1]:\n",
    "  for n_fc_layers in [1, 2]:\n",
    "    for n_conv_layers in [1, 2]:\n",
    "      description = '{}_{}_{}'.format(learning_rate, n_fc_layers, n_conv_layers)\n",
    "      writer = tf.summary.FileWriter('logs/hparams/{}'.format(description))\n",
    "      print(description)\n",
    "      run_mnist(learning_rate, n_fc_layers, n_conv_layers, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TensorBoard.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
